{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Movies Recommendation(Collaborative Filtering).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32bbkRUW4dOH",
        "outputId": "da27c0a9-2319-44da-d97b-fbab7c807689"
      },
      "source": [
        "pip install pyspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/b0/9d6860891ab14a39d4bddf80ba26ce51c2f9dc4805e5c6978ac0472c120a/pyspark-3.1.1.tar.gz (212.3MB)\n",
            "\u001b[K     |████████████████████████████████| 212.3MB 69kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 22.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767604 sha256=bb08cb9253c4c9cda364cc20fcbde62f7688b97feb4325b8229c6b261c918aa4\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/90/c0/01de724414ef122bd05f056541fb6a0ecf47c7ca655f8b3c0f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0HY9B0L6tlJ",
        "outputId": "5ceda717-36b4-4f30-abc8-d6b45c622446"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz7XqKx56u9i"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Movies Recommendation (Collaborative Filtering)\").config(\"spark.driver.memory\",\"15g\").config(\"spark.executor.memory\", \"15g\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkX4UMuH7RMU"
      },
      "source": [
        "# movies = spark.read.load(\"/content/drive/MyDrive/Colab Notebooks/movie/movies.csv\", format='csv', header = True)\n",
        "# ratings = spark.read.load(\"/content/drive/MyDrive/Colab Notebooks/movie/ratings.csv\", format='csv', header = True)\n",
        "movies = spark.read.load(\"/content/drive/MyDrive/Colab Notebooks/movie/full/movies.csv\", format='csv', header = True)\n",
        "ratings = spark.read.load(\"/content/drive/MyDrive/Colab Notebooks/movie/full/ratings.csv\", format='csv', header = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMm8J8V3zc4P"
      },
      "source": [
        "# movies.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psFYFCBY7iVz"
      },
      "source": [
        "ratings = ratings.select(\"userId\", \"movieId\", \"rating\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3L0BELY7k7j"
      },
      "source": [
        "# ratings.printSchema()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qWphEky7uCW"
      },
      "source": [
        "df = ratings.withColumn('userId', ratings['userId'].cast('int')).\\\n",
        "withColumn('movieId', ratings['movieId'].cast('int')).withColumn('rating', ratings['rating'].cast('float'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZZaYSL17xZR"
      },
      "source": [
        "train, validation, test = df.randomSplit([0.6,0.2,0.2], seed = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czSg2Q6-9CJM"
      },
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
        "                                predictionCol=\"prediction\")\n",
        "\n",
        "def RMSE(predictions):\n",
        "    return evaluator.evaluate(predictions)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21J0A8XL8BMf"
      },
      "source": [
        "from pyspark.ml.recommendation import ALS\n",
        "\n",
        "def GridSearch(train, valid, num_iterations, reg_param, n_factors):\n",
        "    min_rmse = float('inf')\n",
        "    best_n = -1\n",
        "    best_reg = 0\n",
        "    best_model = None\n",
        "    for n in n_factors:\n",
        "        for reg in reg_param:\n",
        "            als = ALS(rank = n, \n",
        "                      maxIter = num_iterations, \n",
        "                      seed = 0, \n",
        "                      regParam = reg,\n",
        "                      userCol=\"userId\", \n",
        "                      itemCol=\"movieId\", \n",
        "                      ratingCol=\"rating\", \n",
        "                      coldStartStrategy=\"drop\")            \n",
        "            model = als.fit(train)\n",
        "            predictions = model.transform(valid)\n",
        "            rmse = RMSE(predictions)     \n",
        "            if rmse < min_rmse:\n",
        "                min_rmse = rmse\n",
        "                best_n = n\n",
        "                best_reg = reg\n",
        "                best_model = model\n",
        "                \n",
        "    pred = best_model.transform(train)\n",
        "    train_rmse = RMSE(pred)\n",
        "    return best_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3W9q3ecm8Kcx"
      },
      "source": [
        "num_iterations = 15\n",
        "ranks = [7, 8, 9]\n",
        "reg_params = [0.1, 0.2, 0.3]\n",
        "\n",
        "# final_model = GridSearch(train, validation, num_iterations, reg_params, ranks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LN1jMONphyBI"
      },
      "source": [
        "from pyspark.ml.recommendation import ALS\n",
        "\n",
        "als = ALS(\n",
        "            rank = 9, \n",
        "            maxIter = 15, \n",
        "            seed = 0, \n",
        "            regParam = 0.2,\n",
        "            userCol=\"userId\", \n",
        "            itemCol=\"movieId\", \n",
        "            ratingCol=\"rating\", \n",
        "            coldStartStrategy=\"drop\"\n",
        "            )            \n",
        "final_model = als.fit(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AGw7qpK-QQT",
        "outputId": "7aeac2d7-1337-4c24-d0b1-375b77d45363"
      },
      "source": [
        "pred_test = final_model.transform(test)\n",
        "print ('The testing RMSE is ' + str(RMSE(pred_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The testing RMSE is 0.8692651003430641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBYXCHoK-si4"
      },
      "source": [
        "user_id = [[17]]\n",
        "# convert this into a dataframe so that it can be passed into the recommendForUserSubset\n",
        "functiondf = spark.sparkContext.parallelize(user_id).toDF(['userId'])\n",
        "num_rec = 10\n",
        "recommendations = final_model.recommendForUserSubset(functiondf , num_rec)\n",
        "recommendations.collect()\n",
        "# pick only the ISBN of the books, ignore other fields\n",
        "recommended_ISBN = [recommendations.collect()[0]['recommendations'][x]['movieId'] for x in range(0,num_rec)]\n",
        "# recommended_ISBN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y99HttUaBnI1"
      },
      "source": [
        "# movies.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riHo1f-ZAel5",
        "outputId": "731145b1-6db9-4d08-c212-62da9a946176"
      },
      "source": [
        "from pyspark.sql.types import IntegerType\n",
        "from pyspark.sql.functions import col\n",
        "rec_df = spark.createDataFrame(recommended_ISBN, IntegerType())\n",
        "# rec_df.show()\n",
        "# print('Top ',num_rec,' book recommendations for User-ID ',user_id[0][0], ' are:')\n",
        "movies.join(rec_df,rec_df.value==movies.movieId).select(col('movieId'),col('title'),col('genres')).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+--------------------+------------------+\n",
            "|movieId|               title|            genres|\n",
            "+-------+--------------------+------------------+\n",
            "| 185659|Macho Madness - T...|(no genres listed)|\n",
            "| 159761|         Loot (1970)|      Comedy|Crime|\n",
            "| 187157|Cooking with Love...|    Comedy|Romance|\n",
            "| 182781|Amori che non san...|      Comedy|Drama|\n",
            "| 182489|12 Men of Christm...|    Comedy|Romance|\n",
            "| 151989|    The Thorn (1971)|            Comedy|\n",
            "| 107434|Diplomatic Immuni...|            Comedy|\n",
            "| 107252|Island at War (2004)|         Drama|War|\n",
            "| 192261|Don't Laugh at My...|      Comedy|Drama|\n",
            "|   8394| Hi-Line, The (1999)|             Drama|\n",
            "+-------+--------------------+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}